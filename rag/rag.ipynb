{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Vector embeddings\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "print(os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(https://www.llm-book.com)\\nUpdate: This post has now become a book! Check out LLM-book.com (https://llm-book.com) which\\ncontains (Chapter 3) an updated and expanded version of this post speaking about the latest\\nTransformer models and how they've evolved in the seven years since the original Transformer (like\\nMulti-Query Attention and RoPE Positional embeddings).\\nIn the previous post, we looked at Attention (https://jalammar.github.io/visualizing-neural-machine-translation-\\nmechanics-of-seq2seq-models-with-attention/) – a ubiquitous method in modern deep learning models. Attention is a\\nconcept that helped improve the performance of neural machine translation applications. In this post, we will look at\\nThe Transformer – a model that uses attention to boost the speed with which these models can be trained. The\\nTransformer outperforms the Google Neural Machine Translation model in specific tasks. The biggest benefit,\\nhowever, comes from how The Transformer lends itself to parallelization. It is in fact Google Cloud’s recommendation\\nto use The Transformer as a reference model to use their Cloud TPU (https://cloud.google.com/tpu/) offering. So let’s\\ntry to break the model apart and look at how it functions.\\nThe Transformer was proposed in the paper Attention is All You Need (https://arxiv.org/abs/1706.03762). A TensorFlow\\nimplementation of it is available as a part of the Tensor2Tensor (https://github.com/tensorflow/tensor2tensor) package.\\nHarvard’s NLP group created a guide annotating the paper with PyTorch implementation\\n(http://nlp.seas.harvard.edu/2018/04/03/attention.html). In this post, we will attempt to oversimplify things a bit and\\nintroduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of\\nthe subject matter.\\n2020 Update: I’ve created a “Narrated Transformer” video which is a gentler approach to the topic:\\n1/6/25, 10:27 PM The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.\\nhttps://jalammar.github.io/illustrated-transformer/ 2/43\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from PDF\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader=PyPDFLoader(\"Attention.pdf\")\n",
    "pdf_documents=loader.load()\n",
    "pdf_documents[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(pdf_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKU493\\AppData\\Local\\Temp\\ipykernel_7340\\3527942283.py:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings =OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "embeddings =OpenAIEmbeddings()\n",
    "cromadb=Chroma.from_documents(documents,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm=ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Design ChatPrompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context. \n",
    "Think step by step before providing a detailed answer. \n",
    "I will tip you $1000 if the user finds the answer helpful. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {input}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chain Introduction\n",
    "## Create Stuff Docment Chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001B2E6445FD0>, search_kwargs={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever=cromadb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=retrieval_chain.invoke({\"input\":\"Count Encoder and Decoders Layers in the PDF\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the Transformer model discussed consists of a stack of encoders and decoders. According to the text, the encoding component is a stack of encoders, and the paper mentions stacking six of them on top of each other. Similarly, the decoding component is a stack of decoders of the same number. Therefore, there are six encoder layers and six decoder layers in the Transformer model described.\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
